\documentclass[12pt,journal,compsoc]{IEEEtran}
\providecommand{\PSforPDF}[1]{#1}
\usepackage{algorithm2e}
\newcommand\MYhyperrefoptions{bookmarks=true,bookmarksnumbered=true,
pdfpagemode={UseOutlines},plainpages=false,pdfpagelabels=true,
colorlinks=true,linkcolor={black},citecolor={black},pagecolor={black},
urlcolor={black},
pdftitle={DCPT tweaks},
pdfsubject={Prefetcher},
pdfauthor={Leif Tore Rusten, Stian Fredrikstad, Vegar K\aa sli},
pdfkeywords={dcpt,rpt,prefetcher}}
\hyphenation{op-tical net-works semi-conduc-tor}


\begin{document}
\title{DCPT tweaks \\ Working title}
\author{Leif Tore Rusten,
        Stian Fredrikstad,
        and Vegar K\aa sli}

\markboth{DCPT tweaks}%
{DCPT tweaks}

\IEEEcompsoctitleabstractindextext{%
\begin{abstract}
%\boldmath
This paper will explain some tweaks to the DCPT algorithm and compare speedups to the "original" DCPT
\end{abstract}
% IEEEtran.cls defaults to using nonbold math in the Abstract.
% This preserves the distinction between vectors and scalars. However,
% if the journal you are submitting to favors bold math in the abstract,
% then you can use LaTeX's standard command \boldmath at the very start
% of the abstract to achieve this. Many IEEE journals frown on math
% in the abstract anyway. In particular, the Computer Society does
% not want either math or citations to appear in the abstract.

% Note that keywords are not normally used for peerreview papers.
\begin{IEEEkeywords}
DCPT, RPT, prefetcher
\end{IEEEkeywords}}


% make the title area
\maketitle


% To allow for easy dual compilation without having to reenter the
% abstract/keywords data, the \IEEEcompsoctitleabstractindextext text will
% not be used in maketitle, but will appear (i.e., to be "transported")
% here as \IEEEdisplaynotcompsoctitleabstractindextext when compsoc mode
% is not selected <OR> if conference mode is selected - because compsoc
% conference papers position the abstract like regular (non-compsoc)
% papers do!
\IEEEdisplaynotcompsoctitleabstractindextext
% \IEEEdisplaynotcompsoctitleabstractindextext has no effect when using
% compsoc under a non-conference mode.


% For peer review papers, you can put extra information on the cover
% page as needed:
% \ifCLASSOPTIONpeerreview
% \begin{center} \bfseries EDICS Category: 3-BBND \end{center}
% \fi
%
% For peerreview papers, this IEEEtran command inserts a page break and
% creates the second title. It will be ignored for other modes.
\IEEEpeerreviewmaketitle



\section{Introduction}
Prefetcher has been a hot topic the last years since the memory gap has become so big.
\section{Methodology}
%This section should describe how we attempt to solve our problems.

The methodology used in the beginning was to start with a sequential
prefetcher and briefly progress through prior art, i.e. an RPT implementation
and finally a DCPT implementation. During development the performance was
measured by running a M5-simulator testbench framework and the obtained test
results where evaluated against previous versions' results for
empirically determining the usefulness of the modification.

The prefetcher development has been driven by ideas from the group and it
has been a low barrier for implementing ideas. The ideas proposed have been
thought to be improvements mostly because of personal or group reflection over
the current prefetching mechanism and the memory hierarchy. Testing of
many different modifications and following performance evaluations have been
done rapidly.

So far the development can be seen as searching somewhat blindly for a good
solution. The proposed modifications have often been based on an insight
about the currently implemented prefetcher's (seq, RPT or DCPT) functionality.
Other modifications are mere tweaks of parameters for the different prefetcher
strategies for fine-tuning the performance metrics. Since the main focus of
our research is on the DCPT prefetcher and the development methodology
outlined above (basicly the group using its creativity) will probably only
give a noteworthy performance increase by chance. And even though such
modifications could have been based on a justified/rational idea spurred by
creativity, it would have been better if they where based on measurements and
novel memory access patterns derived from an analytical method.

This means that a shift of methodology probably is required to make truly
interesting discoveries academically and make it more likely to find and
exploit prefetching opportunities. For the remaining work the use of valgrind
and the inspection of which code snippets give cache misses and trying to
analyse these to find potential underlying factors/mechanisms for these
will become a more important tool as we run out of good a priori
insights/ideas.

\section{"The Scheme"}
\subsection{Sequential (seq)}
The framework contained a sequential prefetcher as a starting point.
Using this we created a trivial test program (accumulate.c) that accessed
a large sequential chunk of memory in a tight loop body to assess the
optimal prefetch distance for this type of code structure.
This estimates the best possible performance gain for sequential
prefetching for the shortest possible loop body and this
measured optimum also acts as an upper bound for how many elements should
be present in cache to overlap the time it takes to prefetch enough new
elements to refill the consumption of elements from cache. The optimal
prefetch distance was found to be 4. % TODO Verify this.
% Did we test for optimal degree also?

\subsection{Reference Prediction Table (RPT)}
Modifications related to the prefetch distance and degree where tried.
% An example? Maybe it was with the sequential failback these parameters
% where relevant? TODO check the repo history for modifications to RPT.

Fine-tuning regarding table size and replacement policy.
% Table of the different speedups and which parameters used?

Also different criteria for sequential prefetching failback where tried.
% Or was it? I seem to think so at least. Find the change and document it.

% Also add results to the different modifications/versions and try to explain
% them.

\subsection{Delta Correlating Prediction Table (DCPT) with sequential fallback}
The algorithm for DCPT (Delta Correlating Prediction Table) is based on the pseudo code from \cite{dcptpaper}.
The algorithm is related to RPT, but the difference is that it looks for a pattern instead of one stride.
When the it gets a request, it saves the (PC) program counter, and the stride in a table connected to each PC. When it has more than two elements in the list with strides, it starts looking for patterns.
If it finds a pattern in the list, it saves all the adresses that possibly should be prefetched in another list with candidates for prefetch.
Then it runs through the list and checks if the adresses is not in the cache, in the mshr or that the adress is out of memory. If all the requirements are met, it issues a prefetch for it.

If it has less than two deltas in the list or if it cant find a pattern, it starts prefetching the next block.

Attempts to tweak this implementation:
\begin{itemize}
\item Make a copy of the queue to keep track of which adresses that still aren't fetched, to avoid "double fetching".
\item Make a lru which prevents the prefetcher from throwing out recently used history from the list.
\item Adjustments to the size of the list, and size of the delta list
\end{itemize}

\begin{algorithm}[H]
\dontprintsemicolon
\KwIn{stat}

\Begin{
 $i \leftarrow TABLE[stat.pc]$\;
 \If{$i \neq 0$}{
  $DELTA \leftarrow stat.mem\_addr - i.last\_mem\_addr$\;
  $i.deltas[ ] \leftarrow DELTA$\;
 }
 $i.last\_mem\_addr \leftarrow stat.mem\_addr$\;
 $TABLE[stat.pc] \leftarrow i$\;
 $candidates \leftarrow []$\;
 \If{$size(I.deltas) > 1$}{
   $candidates \leftarrow DCPT(i)$\;
   $prefetch(candidates)$\;
 }
 \If{$size(candidates) == 0$ {\bf and} $canPrefetch(NEXT\_BLOCK)$}{
  $issue\_prefetch(NEXT\_BLOCK)$\;
 }
}
\caption{prefetch\_access\label{pa}}
\end{algorithm}

\begin{algorithm}[H]
\dontprintsemicolon
\KwIn{addr}

\Begin{
 ${\bf return}$ $addr < MAX\_PHYS\_ADDR$ \\
	{\bf and} $!in\_mshr\_queue(addr)$ \\
	{\bf and} $!in\_cache(addr)$ \\
	{\bf and} $!in\_cache\_queue(addr)$\;
}
\caption{canPrefetch\label{cp}}
\end{algorithm}

\begin{algorithm}[H]
\dontprintsemicolon
\KwIn{i}

\Begin{
 $last\_delta\_i \leftarrow i.deltas.last$\;
 \ForEach{$U, V \in reversed(i.deltas)$}{
  \If{$U == i.deltas[last\_delta\_i]$ {\bf and} $V == i.deltas[last\_delta\_i - 1]$}{
   $match\_i \leftarrow indexof(U)$\;	
   ${\bf break}$\;
  }
 }
 $candidates \leftarrow []$\;
 \While{$match\_i < size(i.deltas)$}{
  $candidates \leftarrow i.last\_mem\_addr$ + $i.deltas[++match\_i]$\;
 }
 ${\bf return}$ $candidates$\;
}
\caption{DCPT\label{dcpt}}
\end{algorithm}

\begin{algorithm}[H]
\dontprintsemicolon
\KwIn{candidates}

\Begin{
 \ForEach{$I \in candidates$}{
  \If{$canPrefetch(I)$}{
   $issuePrefetch(I)$\; 
  }
 }
}
\caption{prefetch\label{pre}}
\end{algorithm}


\chapter{Results}
\section{Delta Correlation Prediction Table}
The first implementation of DCPT was not right according to the pseudocode in \cite{dcptpaper}, but it accomplish a 8.6\% speedup with a table of 100 entries and 10 delta per entry.
The attempts to tweak this with other values have not been successful, but it gives around 8\% speedup.
Attempts to add a check to issue less prefetches does also lead to less speedup.

The next implementation, which should be right according to the pseudocode in \cite{dcptpaper} did not do as well, a maximum of 7.3\% speedup with the same specification as the first implementation was accomplished.

\section{Sequential failover}
Look at the pretty plot! This took all to long to generate so the accompanying
informative text will have to wait until I have caught some zzz.

\includegraphics{sequential_failover_speedup_plt}\section{Conclusion}

\section{Further Work}
This section is optional, but might become large.

\subsection{Stuff we will look into before delivery (i.e. our plan forward)}
Continuing to tweak and implement the modified regular DCPT. The plan is
to work with this in March and cut off the gathering of results 1. April
and start focusing on writing the report and presentation.

Look into the generalization of DCPT as a tree-structure. If this gives
ok speedup then we will change the focus of the report into comparing this
approach with our version of DCPT. If performance is low, only mention the
design and do not analyse it further, instead focus on analysing our
DCPT version.

The tree-generalization of DCPT is outlined somewhat as follows. Each new PC
causing an access gets a tree-root-node and two tree-pointers allocated.
As this access is the first access for the PC, no history is available.
Therefore add a child node to the PC's root and associate the stride 1 with it.
Move one of the tree-pointers, cur\_prefetch to this child, and leave the other
pointer, true\_access, alone. At next access for this PC verify if this access
has been correctly prefetched by traversing from cur\_prefetch and up to the
root, checking if any node correspond to the access. If this is the case,
move true\_access to that node. If no such node is found, search the children
of true\_access and check for a stride giving this access. If child found, move
true\_access to this and start prefetching from this nodes subtree and move
cur\_prefetch accordingly. If no child found create a new child node and set
its stride to 1 as in the starting case. These starting or learning cases
are such that if the stride 1 is guessed wrong, correct the stride in the node
instead of creating a new child node, but after this set the node as no longer
learning.

\subsection{Stuff we won't have time to, but that might be good ideas}

%\appendices
%\section{}
%Appendix one text goes here.

% you can choose not to have a title for an appendix
% if you want by leaving the argument blank
%\section{}
%Appendix two text goes here.


% use section* for acknowledgement
\ifCLASSOPTIONcompsoc
  % The Computer Society usually uses the plural form
%  \section*{Acknowledgments}
\else
  % regular IEEE prefers the singular form
%  \section*{Acknowledgment}
\fi


% Can use something like this to put references on a page
% by themselves when using endfloat and the captionsoff option.
\ifCLASSOPTIONcaptionsoff
  \newpage
\fi



\begin{thebibliography}{1}

\bibitem{dcptpaper}
M.~Grann\ae s, M.~Jahre and L.~Natvig, \emph{Storage Efficient Hardware Prefetching using Delta Correlating Prediction Tables}, 2009.

\end{thebibliography}



% that's all folks
\end{document}


