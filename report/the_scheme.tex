\chapter{The scheme}
% A short description of what we will present --- what we have done.

\section{Sequential (seq)}
The framework contained a sequential prefetcher as a starting point.
Using this we created a trivial test program (accumulate.c) that accessed
a large sequential chunk of memory in a tight loop body to assess the
optimal prefetch distance for this type of code structure.
This estimates the best possible performance gain for sequential
prefetching for the shortest possible loop body and this
measured optimum also acts as an upper bound for how many elements should
be present in cache to overlap the time it takes to prefetch enough new
elements to refill the consumption of elements from cache. The optimal
prefetch distance was found to be 4. % TODO Verify this.
% Did we test for optimal degree also?

\section{Reference Prediction Table (RPT)}
Modifications related to the prefetch distance and degree where tried.
% An example? Maybe it was with the sequential failback these parameters
% where relevant? TODO check the repo history for modifications to RPT.

Fine-tuning regarding table size and replacement policy.
% Table of the different speedups and which parameters used?

Also different criteria for sequential prefetching failback where tried.
% Or was it? I seem to think so at least. Find the change and document it.

% Also add results to the different modifications/versions and try to explain
% them.

\section{Delta Correlating Prediction Table (DCPT)}
The algorithm for DCPT (Delta Correlating Prediction Table) is based on the pseudo code from \cite{dcptpaper}.
The implementation is very near RPT, but the difference is that it looks for a pattern instead of one stride.
When the it gets a request, it saves the (PC) program counter, and the stride in a table connected to each PC. When it has more than two elements in the list with strides, it starts looking for patterns.
If it finds a pattern in the list, it saves all the adresses that possibly should be prefetched in another list with candidates for prefetch.
Then it runs through the list and checks if the adresses is not in the cache, in the mshr or that the adress is out of memory. If all the requirements are met, it issues a prefetch for it.

Attempts to tweak this implementation:
- Make a copy of the queue to keep track of which adresses that still aren't fetched, to avoid "double fetching".
- Make a lru which prevents the prefetcher from throwing out recently used history from the list.
- Adjustments to the size of the list, and size of the delta list


